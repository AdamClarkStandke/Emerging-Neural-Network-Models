{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyO8o+XHc7FQ1aUjTh+NPp+j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdamClarkStandke/Emerging-Neural-Network-Models/blob/main/SiameseNetwork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Meta Learning: Siamese Networks\n",
        "\n",
        "Siamese Networks are a form of Meta Learning and is considered to be an emerging neural netwok design, similar to transfer leaning but differnt. As the author of the book titled [Advanced Deep Learning with Python](https://www.amazon.com/Advanced-Deep-Learning-Python-next-generation/dp/178995617X) details:\n",
        "\n",
        "> Meta Learning, also referred to as learning to learn, allows machine learning (ML) algorithms to leverage and channel knowledge, gained over multiple training tasks, to improve its training efficiency over a new task...[this form of learning] has the ability to train with fewer samples...[allowing] for reduced training time and good perfromance when there is not enough traning data.\n",
        "\n",
        "Siamese networks were proposed in the paper [Siamese Neural Netowrks for One shot Image Reconation](https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf). As the authors of the paper detail:\n",
        "\n",
        "> In this paper, we explore a method for learning siamese neural networks which employ a unique structure to naturally rank similarity between inputs. Once a network has been tuned, we can then capitalize on powerful discriminative features to generalize the predictive power of the network not just to new data, but to entirely new classes from unknown distributions.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SBar-b8yP6f2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating equal number of true/false pairs of samples and Loading the MNIST Data\n",
        "\n",
        "I will be implementing the Siamese Network as detailed in the book [Advanced Deep Learning with Python](https://www.amazon.com/Advanced-Deep-Learning-Python-next-generation/dp/178995617X). Before doing so, a helper function called ```create_pairs``` is created. Since the book trains and tests using the MNIST image dataset, each dataset sample consists of an input pair of two MNIST images and a binary label, which indicates whether they are from the same class\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-lUKCkVpVs7y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5M0ydWoCPtEA"
      },
      "outputs": [],
      "source": [
        "# importing necessary packages\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating the training/testing dataset\n",
        "def create_pairs(inputs: np.ndarray, labels: np.ndarray):\n",
        "  num_classes= 10\n",
        "  digit_indices = [np.where(labels==i)[0] for i in range(num_classes)]\n",
        "  pairs = list()\n",
        "  labels = list()\n",
        "  n = min([len(digit_indices[d]) for d in range(num_classes)]) - 1\n",
        "  for d in range(num_classes):\n",
        "    for i in range(n):\n",
        "      z1, z2 = digit_indices[d][i], digit_indices[d][i + 1]\n",
        "      pairs += [[inputs[z1], inputs[z2]]]\n",
        "      inc = random.randrange(1, num_classes)\n",
        "      dn = (d + inc) % num_classes\n",
        "      z1, z2 = digit_indices[d][i], digit_indices[dn][i]\n",
        "      pairs += [[inputs[z1], inputs[z2]]]\n",
        "      labels += [1, 0]\n",
        "  return np.array(pairs), np.array(labels, dtype=np.float32)"
      ],
      "metadata": {
        "id": "ps58q06SglXl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the train and test MNIST datasets\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train = x_train.astype(np.float32)\n",
        "x_test = x_test.astype(np.float32)\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "# Create true/false training and testing pairs\n",
        "train_pairs, tr_labels = create_pairs(x_train, y_train)\n",
        "test_pairs, test_labels = create_pairs(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWE_f3iIhtue",
        "outputId": "0fc134d6-ae8a-419a-9761-e677c3a4787e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating the Base Network of the Siamese System\n",
        "\n",
        "This portion of code will implement the base network of the Siamese System, in which two idential base networks (with shared parameters) are used to output embedding vectors."
      ],
      "metadata": {
        "id": "5_iskIO1fUkS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_base_network():\n",
        "    \"\"\"The shared encoding part of the siamese network\"\"\"\n",
        "\n",
        "    return tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.1),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.1),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "    ])"
      ],
      "metadata": {
        "id": "oYFSPUAdgq22"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building the Siamese System\n",
        "\n",
        "This code portion will build the Siamese System, which includes the base network, the 2 siamese paths of ```encoder_a ```,and ```encoder_b```, the ```l1_dist measure``` and the combined ```model```. In other words implementing the following formula: $L1=|f_{\\theta}(x_i)-f_{\\theta}(x_j)|$ where $f_{\\theta}$ are ```encoder_a``` and ```encoder_b```"
      ],
      "metadata": {
        "id": "1c8qzLDPiFoi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the siamese network\n",
        "# Start from the shared layers\n",
        "base_network = create_base_network()\n",
        "\n",
        "# Create first half of the siamese system\n",
        "input_a = tf.keras.layers.Input(shape=input_shape)\n",
        "\n",
        "# Note how we reuse the base_network in both halfs\n",
        "encoder_a = base_network(input_a)\n",
        "\n",
        "# Create the second half of the siamese system\n",
        "input_b = tf.keras.layers.Input(shape=input_shape)\n",
        "encoder_b = base_network(input_b)\n",
        "\n",
        "# Create the the distance measure\n",
        "l1_dist = tf.keras.layers.Lambda(lambda embeddings: tf.keras.backend.abs(embeddings[0] - embeddings[1]))\\\n",
        " ([encoder_a, encoder_b])\n",
        "\n",
        "# Final fc layer with a single logistic output for the binary classification\n",
        "flattened_weighted_distance = tf.keras.layers.Dense(1, activation='sigmoid') \\\n",
        "    (l1_dist)\n",
        "\n",
        "# Build the model\n",
        "model = tf.keras.models.Model([input_a, input_b], flattened_weighted_distance)"
      ],
      "metadata": {
        "id": "Fwpn0VwwnEqz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the Validating the model"
      ],
      "metadata": {
        "id": "U43Wofb9oCEA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit([train_pairs[:, 0], train_pairs[:, 1]], tr_labels,\n",
        "          batch_size=128,\n",
        "          epochs=20,\n",
        "          validation_data=([test_pairs[:, 0], test_pairs[:, 1]], test_labels))"
      ],
      "metadata": {
        "id": "A1opT8FRoQqv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}